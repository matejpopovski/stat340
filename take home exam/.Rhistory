1.08, -3.68, -2.47, -2.72, 1.57, -0.97, 2.27)
# insert code here
# a)
hat_a <- max(abs(data))
hat_a
# c)
set.seed(123)
max_abs <- function(data) {
return(max(abs(data)))
}
# Number of bootstrap samples
MCN <- 10000
# Generate bootstrap samples and calculate the estimator for each
bootstrap_estimates <- replicate(MCN, {
sample_data <- sample(data, length(data), replace = TRUE)
max_abs(sample_data)
})
# Calculate 95% confidence interval (2.5th and 97.5th percentiles)
ci_lower <- quantile(bootstrap_estimates, 0.025)
ci_upper <- quantile(bootstrap_estimates, 0.975)
ci_lower
ci_upper
# c)
set.seed(123)
max_abs <- function(data) {
return(max(abs(data)))
}
# Number of bootstrap samples
MCN <- 10000
# Generate bootstrap samples and calculate the estimator for each
bootstrap_estimates <- replicate(MCN, {
sample_data <- sample(data, length(data), replace = TRUE)
max_abs(sample_data)
})
# Calculate 95% confidence interval (2.5th and 97.5th percentiles)
ci_lower <- quantile(bootstrap_estimates, 0.025)
ci_upper <- quantile(bootstrap_estimates, 0.975)
#ci_lower
#ci_upper
# c)
set.seed(123)
max_abs <- function(data) {
return(max(abs(data)))
}
# Number of bootstrap samples
MCN <- 10000
# Generate bootstrap samples and calculate the estimator for each
bootstrap_estimates <- replicate(MCN, {
sample_data <- sample(data, length(data), replace = TRUE)
max_abs(sample_data)
})
# Calculate 95% confidence interval (2.5th and 97.5th percentiles)
ci_lower <- quantile(bootstrap_estimates, 0.025)
ci_upper <- quantile(bootstrap_estimates, 0.975)
ci_lower
ci_upper
knitr::opts_chunk$set(echo=T,eval=T,warning=F,message=F,
fig.width=5,fig.height=4,fig.align="center")
data = c(-1.97, -1.07, 0.61, 3.43, -2.51, 3.35, 3.74, 1.35,
1.08, -3.68, -2.47, -2.72, 1.57, -0.97, 2.27)
set.seed(123)
# Sample size
n <- length(data)
# Calculate the unbiased estimator for 'a'
a_hat_unbiased <- (n + 1) / n * max(abs(data))
a_hat_unbiased
cat("The unbiased point estimate for the parameter 'a' is", round(a_hat_unbiased, 2), "\n")
# Number of Monte Carlo simulations
num_simulations <- 10000
# Initialize a vector to store the unbiased estimators from each simulation
unbiased_estimators <- numeric(num_simulations)
# Perform Monte Carlo simulations
for (i in 1:num_simulations) {
# Generate a sample of the same size as the original data from a uniform distribution
simulated_sample <- runif(n, min = -a_hat_unbiased, max = a_hat_unbiased)
# Calculate the unbiased estimator for the simulated sample
unbiased_estimators[i] <- (n + 1) / n * max(abs(simulated_sample))
}
# Calculate the 95% confidence interval
lower_bound <- quantile(unbiased_estimators, 0.025)
upper_bound <- quantile(unbiased_estimators, 0.975)
cat("The 95% confidence interval for the parameter 'a' is (", round(lower_bound, 2), ", ", round(upper_bound, 2), ")\n")
# insert code here
# a) and b)
hat_a <- max(abs(data))
hat_a
# insert code here
# a) and b)
a_hat_unbiased <- (n + 1) / n * max(abs(data))
a_hat_unbiased
# c)
set.seed(123)
max_abs <- function(data) {
return(max(abs(data)))
}
# Number of bootstrap samples
MCN <- 10000
# Generate bootstrap samples and calculate the estimator for each
bootstrap_estimates <- replicate(MCN, {
sample_data <- sample(data, length(data), replace = TRUE)
max_abs(sample_data)
})
# Calculate 95% confidence interval (2.5th and 97.5th percentiles)
ci_lower <- quantile(bootstrap_estimates, 0.025)
ci_upper <- quantile(bootstrap_estimates, 0.975)
ci_lower
ci_upper
data = c(-1.97, -1.07, 0.61, 3.43, -2.51, 3.35, 3.74, 1.35,
1.08, -3.68, -2.47, -2.72, 1.57, -0.97, 2.27)
# insert code here
# a) and b)
a_hat_unbiased <- (n + 1) / n * max(abs(data))
a_hat_unbiased
# insert code here
# a) and b)
hat_a <- max(abs(data))
hat_a
# insert code here
# a) and b)
a_hat_unbiased <- (n + 1) / n * max(abs(data))
a_hat_unbiased
# c)
set.seed(123)
n <- length(data)
num_simulations <- 10000
unbiased_estimators <- numeric(num_simulations)
for (i in 1:num_simulations) {
simulated_sample <- runif(n, min = -a_hat_unbiased, max = a_hat_unbiased)
unbiased_estimators[i] <- (n + 1) / n * max(abs(simulated_sample))
}
# Calculate the 95% confidence interval
lower_bound <- quantile(unbiased_estimators, 0.025)
upper_bound <- quantile(unbiased_estimators, 0.975)
cat("The 95% confidence interval for the parameter 'a' is (", round(lower_bound, 2), ", ", round(upper_bound, 2), ")\n")
set.seed(123)
true_a <- 3.9
n <- 15
num_simulations <- 10000
unbiased_estimators <- numeric(num_simulations)
for (i in 1:num_simulations) {
simulated_sample <- runif(n, min = -true_a, max = true_a)
unbiased_estimators[i] <- (n + 1) / n * max(abs(simulated_sample))
}
bias <- mean(unbiased_estimators) - true_a
cat("The approximate bias of the estimator when the true value of 'a' is", true_a, "is", bias, "\n")
set.seed(123)
# True value of 'a'
true_a <- 3.9
# Sample size
n <- 15
# Number of Monte Carlo simulations
num_simulations <- 10000
# Initialize a vector to store the unbiased estimators from each simulation
unbiased_estimators <- numeric(num_simulations)
# Perform Monte Carlo simulations
for (i in 1:num_simulations) {
# Generate a sample of size n from a uniform distribution with true 'a'
simulated_sample <- runif(n, min = -true_a, max = true_a)
# Calculate the unbiased estimator for the simulated sample
unbiased_estimators[i] <- (n + 1) / n * max(abs(simulated_sample))
}
# Calculate the bias of the estimator
bias <- mean(unbiased_estimators) - true_a
cat("The approximate bias of the estimator when the true value of 'a' is", true_a, "is", bias, "\n")
x = USArrests$Assault
y = USArrests$Murder
# plot(x,y)
x = USArrests$Assault
y = USArrests$Murder
# plot(x,y)
x = USArrests$Assault
y = USArrests$Murder
plot(x,y)
x = USArrests$Assault
y = USArrests$Murder
#. plot(x,y)
x = USArrests$Assault
y = USArrests$Murder
#  plot(x,y)
x = USArrests$Assault
y = USArrests$Murder
plot(x,y)
# insert code here
# b)
model <- lm(Murder ~ Assault, data = USArrests)
summary(model)
knitr::opts_chunk$set(echo=T,eval=T,warning=F,message=F,
fig.width=5,fig.height=4,fig.align="center")
# insert code here
# Load the dataset
data("USArrests")
x = USArrests$Assault
y = USArrests$Murder
plot(x,y)
# Fit the linear model   Murder=β0+β1Assault
model <- lm(Murder ~ Assault, data = USArrests)
# Print the summary
summary(model)
# Calculate the 95% confidence interval for the slope
confint(model, level = 0.95)
#plot the line
pp <- ggplot( model,
aes(x=USArrests$Assault,y=USArrests$Murder));
x = USArrests$Assault
y = USArrests$Murder
plot(x,y)
# insert code here
# Load the dataset
data("USArrests")
x = USArrests$Assault
y = USArrests$Murder
plot(x,y)
# Fit the linear model   Murder=β0+β1Assault
model <- lm(Murder ~ Assault, data = USArrests)
# Print the summary
summary(model)
# Calculate the 95% confidence interval for the slope
confint(model, level = 0.95)
#plot the line
pp <- ggplot( model,
aes(x=USArrests$Assault,y=USArrests$Murder));
library(ggplot2)
# insert code here
# Load the dataset
data("USArrests")
x = USArrests$Assault
y = USArrests$Murder
plot(x,y)
# Fit the linear model   Murder=β0+β1Assault
model <- lm(Murder ~ Assault, data = USArrests)
# Print the summary
summary(model)
# Calculate the 95% confidence interval for the slope
confint(model, level = 0.95)
#plot the line
pp <- ggplot( model,
aes(x=USArrests$Assault,y=USArrests$Murder));
pp <- pp +geom_point() + geom_smooth(method="lm",
formula="y~x",
se=FALSE);
pp <- pp + labs( x="Assult)",
y="Murder",
title="Murder and Assult" )
pp
#residuals
resids <- residuals(model)
hist(resids)
#Homoscedasticity
plot(model, which=1)
plot(model, which=2)
#all standard diagnostic
par(mfrow = c(2, 2))
plot(model)
# d)
t_critical <- qt(0.975, df = 48)
lower_bound <- 0.041909 - t_critical * 0.004507
upper_bound <- 0.041909 + t_critical * 0.004507
c(lower_bound, upper_bound)
x = USArrests$Assault
y = USArrests$Murder
# plot(x,y)
# d)
confint(model, level = 0.95)
t_critical <- qt(0.975, df = 48)
lower_bound <- 0.041909 - t_critical * 0.004507
upper_bound <- 0.041909 + t_critical * 0.004507
c(lower_bound, upper_bound)
# d)
confint(model, level = 0.95)
# check
t_critical <- qt(0.975, df = 48)
lower_bound <- 0.041909 - t_critical * 0.004507
upper_bound <- 0.041909 + t_critical * 0.004507
c(lower_bound, upper_bound)
#plot the line
pp <- ggplot( model,
aes(x=USArrests$Assault,y=USArrests$Murder));
pp <- pp +geom_point() + geom_smooth(method="lm",
formula="y~x",
se=FALSE);
pp <- pp + labs( x="Assult)",
y="Murder",
title="Murder and Assult" )
pp
#residuals
resids <- residuals(model)
hist(resids)
#Homoscedasticity
plot(model, which=1)
plot(model, which=2)
#all standard diagnostic
par(mfrow = c(2, 2))
plot(model)
#plot the line
pp <- ggplot( model,
aes(x=USArrests$Assault,y=USArrests$Murder));
pp <- pp +geom_point() + geom_smooth(method="lm",
formula="y~x",
se=FALSE);
pp <- pp + labs( x="Assult)",
y="Murder",
title="Murder and Assult" )
pp
#residuals
resids <- residuals(model)
hist(resids)
#Homoscedasticity
plot(model, which=1)
plot(model, which=2)
#all standard diagnostic
par(mfrow = c(2, 2))
plot(model)
cables = data.frame(
site = rep(c("Alderwood","Brentwick","Coppergrove"), times=c(53,48,51)),
flaws = c(6,4,4,1,2,1,4,2,4,3,4,8,2,4,6,2,4,1,2,2,0,2,5,2,3,3,3,2,5,4,4,
1,4,3,5,4,4,3,3,4,0,3,4,4,3,5,3,2,1,1,2,3,4,2,5,1,2,2,3,1,2,3,
0,4,2,4,2,2,2,4,4,2,3,5,2,3,2,2,3,1,3,1,1,1,1,0,3,4,4,4,2,2,4,
3,3,2,1,7,3,1,1,3,6,3,7,4,2,3,1,0,4,1,3,4,8,3,3,1,4,3,3,2,2,3,
3,1,0,4,6,3,3,3,7,3,4,3,2,2,4,3,1,4,1,5,3,3,2,3,3,1,3,1)
)
# insert code here
# b) iv)
set.seed(123)
calculate_sad <- function(data) {
sites <- unique(data$site)
combinations <- combn(sites, 2)
sad <- sum(apply(combinations, 2, function(pair) {
abs(mean(data$flaws[data$site == pair[1]]) - mean(data$flaws[data$site == pair[2]]))
}))
return(sad)
}
observed_sad <- calculate_sad(cables)
num_replicates <- 1000
simulated_sad <- replicate(num_replicates, {
shuffled_data <- cables
shuffled_data$flaws <- sample(shuffled_data$flaws)
calculate_sad(shuffled_data)
})
p_value <- mean(simulated_sad >= observed_sad)
cat(sprintf("Observed sum of absolute differences: %f\n", observed_sad))
cat(sprintf("P-value: %f\n", p_value))
if (p_value < 0.05) {
cat("Reject H0: There is a significant difference in the number of flaws between the facilities.\n")
} else {
cat("Fail to reject H0: There is no significant difference in the number of flaws between the facilities.\n")
}
knitr::opts_chunk$set(echo=T,eval=T,warning=F,message=F,
fig.width=5,fig.height=4,fig.align="center")
set.seed(42)
# Given data
cables <- data.frame(
site = rep(c("Alderwood", "Brentwick", "Coppergrove"), times = c(53, 48, 51)),
flaws = c(6, 4, 4, 1, 2, 1, 4, 2, 4, 3, 4, 8, 2, 4, 6, 2, 4, 1, 2, 2, 0, 2, 5, 2, 3, 3, 3, 2, 5, 4, 4,
1, 4, 3, 5, 4, 4, 3, 3, 4, 0, 3, 4, 4, 3, 5, 3, 2, 1, 1, 2, 3, 4, 2, 5, 1, 2, 2, 3, 1, 2, 3,
0, 4, 2, 4, 2, 2, 2, 4, 4, 2, 3, 5, 2, 3, 2, 2, 3, 1, 3, 1, 1, 1, 1, 0, 3, 4, 4, 4, 2, 2, 4,
3, 3, 2, 1, 7, 3, 1, 1, 3, 6, 3, 7, 4, 2, 3, 1, 0, 4, 1, 3, 4, 8, 3, 3, 1, 4, 3, 3, 2, 2, 3,
3, 1, 0, 4, 6, 3, 3, 3, 7, 3, 4, 3, 2, 2, 4, 3, 1, 4, 1, 5, 3, 3, 2, 3, 3, 1, 3, 1)
)
# Calculate the sum of absolute differences
calculate_sad <- function(data) {
sites <- unique(data$site)
combinations <- combn(sites, 2)
sad <- sum(apply(combinations, 2, function(pair) {
abs(mean(data$flaws[data$site == pair[1]]) - mean(data$flaws[data$site == pair[2]]))
}))
return(sad)
}
# Observed sum of absolute differences
observed_sad <- calculate_sad(cables)
# Monte Carlo simulation
num_replicates <- 1000
simulated_sad <- replicate(num_replicates, {
shuffled_data <- cables
shuffled_data$flaws <- sample(shuffled_data$flaws)
calculate_sad(shuffled_data)
})
# Calculate p-value
p_value <- mean(simulated_sad >= observed_sad)
# Output the results
cat(sprintf("Observed sum of absolute differences: %f\n", observed_sad))
cat(sprintf("P-value: %f\n", p_value))
if (p_value < 0.05) {
cat("Reject H0: There is a significant difference in the number of flaws between the facilities.\n")
} else {
cat("Fail to reject H0: There is no significant difference in the number of flaws between the facilities.\n")
}
# insert code here
# b) iv)
set.seed(42)
calculate_sad <- function(data) {
sites <- unique(data$site)
combinations <- combn(sites, 2)
sad <- sum(apply(combinations, 2, function(pair) {
abs(mean(data$flaws[data$site == pair[1]]) - mean(data$flaws[data$site == pair[2]]))
}))
return(sad)
}
observed_sad <- calculate_sad(cables)
num_replicates <- 1000
simulated_sad <- replicate(num_replicates, {
shuffled_data <- cables
shuffled_data$flaws <- sample(shuffled_data$flaws)
calculate_sad(shuffled_data)
})
p_value <- mean(simulated_sad >= observed_sad)
cat(sprintf("Observed sum of absolute differences: %f\n", observed_sad))
cat(sprintf("P-value: %f\n", p_value))
if (p_value < 0.05) {
cat("Reject H0: There is a significant difference in the number of flaws between the facilities.\n")
} else {
cat("Fail to reject H0: There is no significant difference in the number of flaws between the facilities.\n")
}
# insert code here
# b) iv)
set.seed(123)
calculate_sad <- function(data) {
sites <- unique(data$site)
combinations <- combn(sites, 2)
sad <- sum(apply(combinations, 2, function(pair) {
abs(mean(data$flaws[data$site == pair[1]]) - mean(data$flaws[data$site == pair[2]]))
}))
return(sad)
}
observed_sad <- calculate_sad(cables)
num_replicates <- 1000
simulated_sad <- replicate(num_replicates, {
shuffled_data <- cables
shuffled_data$flaws <- sample(shuffled_data$flaws)
calculate_sad(shuffled_data)
})
p_value <- mean(simulated_sad >= observed_sad)
cat(sprintf("Observed sum of absolute differences: %f\n", observed_sad))
cat(sprintf("P-value: %f\n", p_value))
if (p_value < 0.05) {
cat("Reject H0: There is a significant difference in the number of flaws between the facilities.\n")
} else {
cat("Fail to reject H0: There is no significant difference in the number of flaws between the facilities.\n")
}
# Perform ANOVA test
anova_test <- aov(flaws ~ site, data = cables)
summary(anova_test)
anova_test <- aov(flaws ~ site, data = cables)
summary(anova_test)
# insert code here
# a) and b)
a_hat_unbiased <- (n + 1) / n * max(abs(data))
a_hat_unbiased
max(abs(data))
# insert code here
# a) and b)
a_hat_unbiased <- (n + 1) / n * max(abs(data))
a_hat_unbiased
arctan
# e)
#plot the line
pp <- ggplot( model,
aes(x=USArrests$Assault,y=USArrests$Murder));
pp <- pp +geom_point() + geom_smooth(method="lm",
formula="y~x",
se=FALSE);
pp <- pp + labs( x="Assult)",
y="Murder",
title="Murder and Assult" )
pp
#residuals
resids <- residuals(model)
hist(resids)
#Homoscedasticity
plot(model, which=1)
plot(model, which=2)
# e)
#plot the line
pp <- ggplot( model,
aes(x=USArrests$Assault,y=USArrests$Murder));
pp <- pp +geom_point() + geom_smooth(method="lm",
formula="y~x",
se=TRUE);
pp <- pp + labs( x="Assult)",
y="Murder",
title="Murder and Assult" )
pp
#residuals
resids <- residuals(model)
hist(resids)
#Homoscedasticity
plot(model, which=1)
plot(model, which=2)
# e)
#plot the line
pp <- ggplot( model,
aes(x=USArrests$Assault,y=USArrests$Murder));
pp <- pp +geom_point() + geom_smooth(method="lm",
formula="y~x",
se=TRUE);
pp <- pp + labs( x="Assult)",
y="Murder",
title="Murder and Assult" )
pp
#residuals
resids <- residuals(model)
hist(resids)
#Homoscedasticity
plot(model, which=1)
plot(model, which=2)
#all standard diagnostic
par(mfrow = c(2, 2))
plot(model)
# insert code here
# a) and b)
n <- length(data)
a_hat_unbiased <- (n + 1) / n * max(abs(data))
a_hat_unbiased
