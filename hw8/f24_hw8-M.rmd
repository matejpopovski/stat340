---
title: "Homework 8"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
library(tidyverse)
```

## Problem 1: The infamous mule kick data <small>10pts</small>

The file `mule_kicks.csv`, available for download (here)[https://kdlevin-uwstat.github.io/STAT340-Fall2021/hw/03/mule_kicks.csv], contains a simplified version of a very famous data set. The data consists of the number of soldiers killed by being kicked by mules or horses each year in a number of different companies in the Prussian army near the end of the 19th century.

This may seem at first to be a very silly thing to collect data about, but it is a very interesting thing to look at if you are interested in rare events. Deaths by horse kick were rare events that occurred independently of one another, and thus it is precisely the kind of process that we might expect to obey a Poisson distribution.

Download the data and read it into R by running

```{r}
download.file('https://kdlevin-uwstat.github.io/STAT340-Fall2021/hw/03/mule_kicks.csv', destfile='mule_kicks.csv')
mule_kicks = read.csv('mule_kicks.csv', header=TRUE)

head(mule_kicks)
```

`mule_kicks` contains a single column, called `deaths`.
Each entry is the number of soldiers killed in one corps of the Prussian army in one year.
There are 14 corps in the data set, studied over 20 years, for a total of 280 death counts.


### Part a: estimating the Poisson rate <small>3pts</small>

Assuming that the mule kicks data follows a Poisson distribution, produce a point estimate for the rate parameter $\lambda$.
There are no strictly right or wrong answers, here, though there are certainly better or worse ones.
```{r}
lambda_true= 196/(14*20)
lambda_true
```



### Part b: constructing a CI <small>4pts</small>

Using everything you know (Monte Carlo, CLT, etc.), construct a confidence interval for the rate parameter $\lambda$.
Explain in reasonable detail what you are doing and why you are constructing the confidence interval in this way (a few sentences is fine!).

```{r}
set.seed(123)

total_deaths <- 196
total_period <- 280
lambda_hat <- total_deaths / total_period  # Point estimate for lambda
M <- 10000  # Number of Monte Carlo simulations

# Monte Carlo simulation to generate lambda estimates
lambda_estimates <- numeric(M)

for (i in 1:M) {
  simulated_data <- rpois(total_period, lambda_hat)
  lambda_estimates[i] <- mean(simulated_data)
}

# Calculate confidence interval
alpha <- 0.05
lower_bound <- quantile(lambda_estimates, alpha / 2)
upper_bound <- quantile(lambda_estimates, 1 - alpha / 2)

# Print the result
cat("Point estimate for lambda:", lambda_hat, "\n")
cat("95% Confidence interval for lambda: [", lower_bound, ",", upper_bound, "]\n")

# Plot the distribution of lambda estimates
hist(lambda_estimates, breaks = 30, probability = TRUE, main = "Distribution of Lambda Estimates", xlab = "Lambda")
abline(v = c(lower_bound, upper_bound), col = "red", lwd = 2, lty = 2)

```

### Part c: assessing a model <small>3pts</small>

Here's a slightly more open-ended question.
We *assumed* that the data followed a Poisson distribution.
This may or may not be a reasonable assumption.
Use any and all tools that you know to assess (either with code or simply in words) how reasonable or unreasonable this assumption is.

Once again, there are no strictly right or wrong answers here.
Explain and defend your decisions and thought processes in a reasonable way and you will receive full credit.

visual 
```{r}
# Load necessary libraries
library(ggplot2)

# Load your data (assuming data is in a vector called deaths)
 deaths <- read.csv("mule_kicks.csv")$deaths

# Plot histogram of the data
ggplot(data.frame(deaths), aes(x = deaths)) +
  geom_histogram(aes(y = ..density..), bins = 10, fill = 'skyblue', alpha = 0.7) +
  stat_function(fun = dpois, args = list(lambda = mean(deaths)), color = 'red', size = 1) +
  labs(title = "Histogram of Deaths with Poisson Fit",
       x = "Number of Deaths",
       y = "Density")

```

chi2 test
```{r}
# Fit Poisson distribution
lambda_hat <- mean(deaths)
expected_counts <- dpois(0:max(deaths), lambda = lambda_hat) * length(deaths)
observed_counts <- table(factor(deaths, levels = 0:max(deaths)))

# Chi-square test
chisq_test <- chisq.test(observed_counts, p = expected_counts, rescale.p = TRUE)
print(chisq_test)

```

Q-Qplot
```{r}
# Generate Q-Q plot
qqplot(qpois(ppoints(length(deaths)), lambda = lambda_hat), deaths, main = "Q-Q Plot of Deaths vs Poisson Distribution")
qqline(deaths, distribution = function(p) qpois(p, lambda = lambda_hat), col = "red")

```


```{r}
# Calculate variance-to-mean ratio
variance_mean_ratio <- var(deaths) / mean(deaths)
print(paste("Variance-to-Mean Ratio:", variance_mean_ratio))

```



## Problem 2: A Confidence interval for the median (8 points)

The following numbers were sampled from a population. You can assume they are independent and identically distributed (they are, in fact).

```{r}
mysteryData <- c(16.91,19.96,16.55,16.77,19.64,16.87,16.50,14.19,16.54,18.64,11.27,17.08)
```

We want to estimate the population median with a 95\% confidence interval.

a. First assume that the population is normally distributed. Come up with estimates for the parameters of the normal distribution based on the data.

```{r}
# Given data
Data <- c(16.91, 19.96, 16.55, 16.77, 19.64, 16.87, 16.50, 14.19, 16.54, 18.64, 11.27, 17.08)

# Estimate mean (mu) and standard deviation (sigma)
mu <- mean(Data)
sigma <- sd(Data)

cat(sprintf("Estimated mean (mu): %f\n", mu))
cat(sprintf("Estimated standard deviation (sigma): %f\n", sigma))

```
For a normally distributed population, the median is the same as the mean.The confidence interval for mean is:
ð¶ð¼=ðœ‡Â±ð‘ð›¼/2ðœŽ/sqrtð‘›
ðœ‡ is the sample mean
ðœŽ is the sample standard deviation
ð‘›is the sample size
ð‘ð›¼/2  is the Z-value for a 95% confidence interval (approximately 1.96)

```{r}
# Given data
Data <- c(16.91, 19.96, 16.55, 16.77, 19.64, 16.87, 16.50, 14.19, 16.54, 18.64, 11.27, 17.08)

# Estimate mean (mu) and standard deviation (sigma)
mu <- mean(Data)
sigma <- sd(Data)
n <- length(Data)
z <- 1.96  # Z-value for 95% confidence interval

# Calculate the confidence interval
error_margin <- z * sigma / sqrt(n)
lower_bound <- mu - error_margin
upper_bound <- mu + error_margin

cat(sprintf("Estimated mean (mu): %f\n", mu))
cat(sprintf("Estimated standard deviation (sigma): %f\n", sigma))
cat(sprintf("95%% Confidence interval for the population median: [%f, %f]\n", lower_bound, upper_bound))

```




b. Construct a 95\% confidence interval assuming the population is a normal distribution. Use the Monte Carlo Approach. Use 1000 Monte Carlo replicates.
```{r}
set.seed(42)


# Number of Monte Carlo replicates
num_replicates <- 1000
n <- length(Data)
alpha <- 0.05

# Function to generate a Monte Carlo sample and calculate the sample median
generate_sample_median <- function(mu, sigma, n) {
  sample <- rnorm(n, mean = mu, sd = sigma)
  sample_median <- median(sample)
  return(sample_median)
}

# Generate Monte Carlo samples and calculate medians
medians <- replicate(num_replicates, generate_sample_median(mu, sigma, n))

# Calculate the confidence interval using the quantile function
lower_bound <- quantile(medians, alpha / 2)
upper_bound <- quantile(medians, 1 - alpha / 2)

# Output the results
cat(sprintf("Estimated mean (mu): %f\n", mu))
cat(sprintf("Estimated standard deviation (sigma): %f\n", sigma))
cat(sprintf("95%% Confidence interval for the population median: [%f, %f]\n", lower_bound, upper_bound))

```

c. Now assume that the population is uniformly distributed. Come up with estimates for the min and max of the uniform distribution using the method of moments. This is based on $\bar{X}$, the sample mean and $S$, the sample standard deviation. The point estimates for a and b are given by  $$\bar{X} \pm \sqrt{3} S$$ 

```{r}
# Given data
Data <- c(16.91, 19.96, 16.55, 16.77, 19.64, 16.87, 16.50, 14.19, 16.54, 18.64, 11.27, 17.08)

# Calculate the sample mean and standard deviation
mean_X <- mean(Data)
sd_X <- sd(Data)

# Calculate the estimates for a and b
a <- mean_X - sqrt(3) * sd_X
b <- mean_X + sqrt(3) * sd_X

# Output the results
cat(sprintf("Estimated minimum value (a): %f\n", a))
cat(sprintf("Estimated maximum value (b): %f\n", b))

```

d. Construct a 95\% confidence interval assuming the population is a uniform distribution. Use 1000 Monte Carlo replicates.

```{r}
set.seed(42)

# Given data
Data <- c(16.91, 19.96, 16.55, 16.77, 19.64, 16.87, 16.50, 14.19, 16.54, 18.64, 11.27, 17.08)

# Estimate mean (mu) and standard deviation (sigma)
mean_X <- mean(Data)
sd_X <- sd(Data)

# Calculate the estimates for a and b
a <- mean_X - sqrt(3) * sd_X
b <- mean_X + sqrt(3) * sd_X

# Number of Monte Carlo replicates
num_replicates <- 1000
alpha <- 0.05

# Function to generate a Monte Carlo sample and calculate the sample median
generate_sample_median <- function(a, b, n) {
  sample <- runif(n, min = a, max = b)
  sample_median <- median(sample)
  return(sample_median)
}

# Generate Monte Carlo samples and calculate medians
medians <- replicate(num_replicates, generate_sample_median(a, b, length(Data)))

# Calculate the confidence interval using the quantile function
lower_bound <- quantile(medians, alpha / 2)
upper_bound <- quantile(medians, 1 - alpha / 2)

# Output the results
cat(sprintf("Estimated minimum value (a): %f\n", a))
cat(sprintf("Estimated maximum value (b): %f\n", b))
cat(sprintf("95%% Confidence interval for the population median: [%f, %f]\n", lower_bound, upper_bound))

```

## Problem 3: Closing the loop <small>6 pts</small>

In our discussion of the Universal Widgets of Madison company from lecture, we said that we were interested in two questions:

1. Estimating the probability $p$ that a widget is functional.
2. How many widgets should be in a batch to ensure that (with high probability) a batch ships with at least $5$ functional widgets in it?

We discussed question (1) at length in lecture.
What about question (2)?
Our client wants to know how many widgets should ship in each batch so as to ensure that the probability there are at least $5$ functional widgets in a batch is at least $0.99$.

Now, suppose that we have observed data and estimated $p$ to be $0.82$.

Use everything you know so far in this course to give a recommendation to the client.
Be sure to explain clearly what you are doing and why.
If there are any steps, assumptions, etc., that you are not 100% pleased with, feel free to point them out.

__Note:__ there are at least two "obvious" ways to solve this problem. One is based on using Monte Carlo (i.e., assume $p=0.82$ is the truth, and try generating batches of different sizes, etc.).
The other uses direct computation of probabilities, using basic facts about Binomial RVs.
Neither of these is necessarily better than the other, and you do not need to use both approaches to receive full credit.
Indeed, you are free to try doing something else entirely, if you wish.
Just explain clearly what you are doing and why!

```{r}
# Load necessary library
if (!requireNamespace("stats", quietly = TRUE)) {
  install.packages("stats")
}

# Given data
p <- 0.82  # probability of a widget being functional
required_prob <- 0.99  # required probability of having at least 5 functional widgets

# Function to calculate the minimum batch size
min_batch_size <- function(p, required_prob) {
  for (n in 1:1000) {  # Arbitrary large number for upper limit
    prob <- 1 - pbinom(4, n, p)  # Probability of having at least 5 functional widgets
    if (prob >= required_prob) {
      return(n)
    }
  }
  return(NULL)
}

# Calculate the minimum batch size
batch_size <- min_batch_size(p, required_prob)

cat("The minimum batch size to ensure at least 5 functional widgets with a probability of at least", required_prob, "is", batch_size, ".\n")

```
```{r}
# Given data
p <- 0.82  # probability of a widget being functional
required_prob <- 0.99  # required probability of having at least 5 functional widgets
num_simulations <- 10000  # number of simulations

# Function to calculate the minimum batch size using Monte Carlo simulation
min_batch_size_mc <- function(p, required_prob, num_simulations) {
  for (n in 1:1000) {  # Arbitrary large number for upper limit
    successes <- replicate(num_simulations, sum(rbinom(n, 1, p)))
    prob <- mean(successes >= 5)
    if (prob >= required_prob) {
      return(n)
    }
  }
  return(NULL)
}

# Calculate the minimum batch size
set.seed(123)  # for reproducibility
batch_size <- min_batch_size_mc(p, required_prob, num_simulations)

cat("The minimum batch size to ensure at least 5 functional widgets with a probability of at least", required_prob, "is", batch_size, ".\n")

```



## Problem 4: Estimating Coverage Rate (6 points)

Suppose we want to estimate the $p$ parameter from a Geometric distribution. By doing some research you would find that an unbiased estimator for $p$ is given as:

$$\hat{p} = \frac{1}{1+\frac{n}{n-1}\bar{X}}$$ 

a. Create a plot that shows the coverage rate of a 95\% confidence interval for samples of size 12 for values of p: .10, .20, ..., .80, .90. 

* To estimate the coverage rate, use 500 Monte Carlo replicates
* To construct each MC interval you should use 500 MC replicates

If this is taking too long to run, lower both of these to 200 replicates.

> p = 1/(1+x_hat)

```{r}
set.seed(1)
p <- seq(.1,.9,.1)
coverage <- rep(0, length(p))
results <- data.frame(p, coverage)
NMC1 <- 500
NMC2 <- 500

for(j in 1:nrow(results)){
  # pull out the value p from the results data frame
  p <- results$p[j]
  # the 'contains' vector will be a collection of TRUE and FALSE, based
  # on whether each CI contains the value p
  contains <- rep(FALSE, NMC1)
  for(i in 1:NMC1){ #Construct NMC1 confidence intervals
    #generate some data initially from the geometric distribution

    #calculate the unbiased estimate of p
    
    #Now you want to use your p.hat to generate NMC2 sets of data
    #Each time you want to calcualte an unbiased phat, and store it.
    
    #Your Monte Carlo Confidence interval should be based on
    #appropriate sample quantiles
    
    #Last, assign 'contains[i]' to be TRUE or FALSE based on 
    #whether p is >= than the lower bound AND <= the 
    #upper bound. 
  }
  results[j, "coverage"] <- mean(contains)
}
plot(x=results$p, y=results$coverage, ylim=c(min(coverage),1), type="l")
abline(h=.95, lty=2)
```
dovrsen cod
```{r}
set.seed(1)
p_values <- seq(0.1, 0.9, 0.1)
coverage <- rep(0, length(p_values))
results <- data.frame(p = p_values, coverage = coverage)
NMC1 <- 500
NMC2 <- 500
n <- 12  # sample size

for (j in 1:nrow(results)) {
  p <- results$p[j]
  contains <- rep(FALSE, NMC1)
  
  for (i in 1:NMC1) {
    # Generate data from the geometric distribution
    data <- rgeom(n, p)
    x_bar <- mean(data)
    
    # Calculate the unbiased estimate of p
    p_hat <- 1 / (1 + (n / (n - 1)) * x_bar)
    
    # Generate NMC2 sets of data using p_hat
    p_hat_samples <- replicate(NMC2, {
      sample_data <- rgeom(n, p_hat)
      sample_x_bar <- mean(sample_data)
      1 / (1 + (n / (n - 1)) * sample_x_bar)
    })
    
    # Calculate the 95% confidence interval
    ci_lower <- quantile(p_hat_samples, 0.025)
    ci_upper <- quantile(p_hat_samples, 0.975)
    
    # Check if the true p is within the confidence interval
    contains[i] <- (p >= ci_lower) & (p <= ci_upper)
  }
  
  # Calculate the coverage rate
  results[j, "coverage"] <- mean(contains)
}

# Plot the coverage rate
plot(x = results$p, y = results$coverage, ylim = c(min(results$coverage), 1), type = "l",
     xlab = "True p", ylab = "Coverage Rate", main = "Coverage Rate of 95% CI")
abline(h = 0.95, lty = 2)

```


b. What do you observe? Does the coverage of MC intervals tend to be affected by the value of $p$? In what way?

1.	Small ( p ) Values:
For small values of ( p ) (up to around 0.3), the estimator (\hat{p}) tends to perform well, and the coverage rate is close to the nominal 95%. This is because the variance of the estimator is relatively low, and the distribution of the estimator is more symmetric.
2.	Moderate ( p ) Values:
As ( p ) increases towards 0.5, the variance of the estimator increases, and the distribution becomes more skewed. This can lead to wider confidence intervals that may not capture the true ( p ) as effectively, resulting in a drop in the coverage rate.
3.	Extreme ( p ) Values:
For very high values of ( p ) (close to 0.9), the estimator (\hat{p}) becomes highly variable and biased. The confidence intervals become less reliable, and the coverage rate drops sharply.


