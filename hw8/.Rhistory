# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts[1]
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts[][1]
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts[][2]
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts[1][]
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts[2][]
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts[0][1]
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts[0][2]
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts[0][0]
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
# Observed counts and expected frequencies
counts <- table(mule_kicks$deaths)
expected_counts <- dpois(as.numeric(names(counts)), lambda = sample_mean) * length(mule_kicks$deaths)
counts
expected_counts
# Chi-squared test
chisq_test <- chisq.test(counts, p = expected_counts, rescale.p = TRUE)
chisq_test
mysteryData <- c(16.91,19.96,16.55,16.77,19.64,16.87,16.50,14.19,16.54,18.64,11.27,17.08)
mean_estimate <- mean(mysteryData)
sd_estimate <- sd(mysteryData)
mean_estimate
sd_estimate
n_replicates <- 1000
sample_size <- length(mysteryData)
# Monte Carlo simulation
set.seed(123)  # Set seed for reproducibility
monte_carlo_medians <- replicate(n_replicates, {
# Generate a random sample from a normal distribution
simulated_sample <- rnorm(sample_size, mean = mean_estimate, sd = sd_estimate)
# Calculate the median of the simulated sample
median(simulated_sample)
})
# Calculate the 95% confidence interval for the median
ci_lower <- quantile(monte_carlo_medians, 0.025)
ci_upper <- quantile(monte_carlo_medians, 0.975)
# Print the results
ci_lower
ci_upper
set.seed(123)
n_replicates <- 1000
sample_size <- length(mysteryData)
# Monte Carlo simulation
monte_carlo_medians <- replicate(n_replicates, {
simulated_sample <- rnorm(sample_size, mean = mean_estimate, sd = sd_estimate)
median(simulated_sample)
})
ci_lower <- quantile(monte_carlo_medians, 0.025)
ci_upper <- quantile(monte_carlo_medians, 0.975)
ci_lower
ci_upper
a_estimate <- mean_estimate - sqrt(3) * sd_estimate
b_estimate <- mean_estimate + sqrt(3) * sd_estimate
a_estimate
b_estimate
set.seed(123)
n_replicates <- 1000
monte_carlo_a <- numeric(n_replicates)
monte_carlo_b <- numeric(n_replicates)
for (i in 1:n_replicates) {
simulated_sample <- runif(length(mysteryData), min = a_estimate, max = b_estimate)
sample_mean <- mean(simulated_sample)
sample_sd <- sd(simulated_sample)
monte_carlo_a[i] <- sample_mean - sqrt(3) * sample_sd
monte_carlo_b[i] <- sample_mean + sqrt(3) * sample_sd
}
ci_a_lower <- quantile(monte_carlo_a, 0.025)
ci_a_upper <- quantile(monte_carlo_a, 0.975)
ci_b_lower <- quantile(monte_carlo_b, 0.025)
ci_b_upper <- quantile(monte_carlo_b, 0.975)
ci_a_lower
ci_a_upper
ci_b_lower
ci_b_upper
set.seed(123)
p <- 0.82
# Function to simulate a batch of widgets and check if at least 5 are functional
simulate_batch <- function(batch_size) {
# Generate a batch of widgets, 1 represents functional, 0 non-functional
batch <- rbinom(batch_size, 1, p)
# Check if at least 5 are functional
return(sum(batch >= 5))
}
# Function to estimate the minimum batch size for 99% probability
find_batch_size <- function(target_prob, max_size = 100) {
for (batch_size in 5:max_size) {
results <- replicate(10000, simulate_batch(batch_size))
prob_at_least_5 <- mean(results >= 5)
if (prob_at_least_5 >= target_prob) {
return(batch_size)
}
}
return(NA) # if no size meets the probability
}
# Find the minimum batch size that ensures at least 5 functional widgets with 99% probability
min_batch_size_mc <- find_batch_size(0.99)
cat("Monte Carlo Approach - Minimum batch size: ", min_batch_size_mc, "\n")
set.seed(123)
p <- 0.82
# Function to simulate a batch of widgets and check if at least 5 are functional
simulate_batch <- function(batch_size) {
# Generate a batch of widgets, 1 represents functional, 0 non-functional
batch <- rbinom(batch_size, 1, p)
# Check if at least 5 are functional
return(sum(batch >= 5))
}
# Function to estimate the minimum batch size for 99% probability
find_batch_size <- function(target_prob, max_size = 100) {
for (batch_size in 5:max_size) {
results <- replicate(10000, simulate_batch(batch_size))
prob_at_least_5 <- mean(results >= 5)
if (prob_at_least_5 >= target_prob) {
return(batch_size)
}
}
return(NA) # if no size meets the probability
}
# Find the minimum batch size that ensures at least 5 functional widgets with 99% probability
min_batch_size_mc <- find_batch_size(0.99)
cat("Monte Carlo Approach - Minimum batch size: ", min_batch_size_mc, "\n")
set.seed(42)
p <- 0.82
# Function to simulate a batch of widgets and check if at least 5 are functional
simulate_batch <- function(batch_size) {
# Generate a batch of widgets, 1 represents functional, 0 non-functional
batch <- rbinom(batch_size, 1, p)
# Check if at least 5 are functional
return(sum(batch >= 5))
}
# Function to estimate the minimum batch size for 99% probability
find_batch_size <- function(target_prob, max_size = 100) {
for (batch_size in 5:max_size) {
results <- replicate(10000, simulate_batch(batch_size))
prob_at_least_5 <- mean(results >= 5)
if (prob_at_least_5 >= target_prob) {
return(batch_size)
}
}
return(NA) # if no size meets the probability
}
# Find the minimum batch size that ensures at least 5 functional widgets with 99% probability
min_batch_size_mc <- find_batch_size(0.99)
cat("Monte Carlo Approach - Minimum batch size: ", min_batch_size_mc, "\n")
set.seed(42)
# Given probability of functional widget
p <- 0.82
# Function to simulate a batch of widgets and check if at least 5 are functional
simulate_batch <- function(batch_size) {
# Generate a batch of widgets, 1 represents functional, 0 non-functional
batch <- rbinom(batch_size, 1, p)
# Check if at least 5 are functional
return(sum(batch >= 5))
}
# Function to estimate the minimum batch size for 99% probability
find_batch_size <- function(target_prob, max_size = 200) {
for (batch_size in 5:max_size) {
# Simulate 10000 batches and check the proportion with at least 5 functional widgets
results <- replicate(10000, simulate_batch(batch_size))
# Calculate probability of having at least 5 functional widgets in a batch
prob_at_least_5 <- mean(results >= 5)
cat("Batch size:", batch_size, "Probability of at least 5 functional widgets:", prob_at_least_5, "\n")
if (prob_at_least_5 >= target_prob) {
return(batch_size)
}
}
return(NA) # if no size meets the probability
}
# Find the minimum batch size that ensures at least 5 functional widgets with 99% probability
min_batch_size_mc <- find_batch_size(0.99)
cat("Monte Carlo Approach - Minimum batch size:", min_batch_size_mc, "\n")
set.seed(42)
# Given probability of functional widget
p <- 0.82
# Function to simulate a batch of widgets and check if at least 5 are functional
simulate_batch <- function(batch_size) {
# Generate a batch of widgets, 1 represents functional, 0 non-functional
batch <- rbinom(batch_size, 1, p)
# Check if at least 5 widgets are functional (i.e., sum of 1's in the batch)
return(sum(batch) >= 5)
}
# Function to estimate the minimum batch size for 99% probability
find_batch_size <- function(target_prob, max_size = 200) {
for (batch_size in 5:max_size) {
# Simulate 10000 batches and check the proportion with at least 5 functional widgets
results <- replicate(10000, simulate_batch(batch_size))
# Calculate probability of having at least 5 functional widgets in a batch
prob_at_least_5 <- mean(results)
cat("Batch size:", batch_size, "Probability of at least 5 functional widgets:", prob_at_least_5, "\n")
if (prob_at_least_5 >= target_prob) {
return(batch_size)
}
}
return(NA) # if no size meets the probability
}
# Find the minimum batch size that ensures at least 5 functional widgets with 99% probability
min_batch_size_mc <- find_batch_size(0.99)
cat("Monte Carlo Approach - Minimum batch size:", min_batch_size_mc, "\n")
set.seed(123)
# Given probability of functional widget
p <- 0.82
# Function to simulate a batch of widgets and check if at least 5 are functional
simulate_batch <- function(batch_size) {
# Generate a batch of widgets, 1 represents functional, 0 non-functional
batch <- rbinom(batch_size, 1, p)
# Check if at least 5 widgets are functional (i.e., sum of 1's in the batch)
return(sum(batch) >= 5)
}
# Function to estimate the minimum batch size for 99% probability
find_batch_size <- function(target_prob, max_size = 200) {
for (batch_size in 5:max_size) {
# Simulate 10000 batches and check the proportion with at least 5 functional widgets
results <- replicate(10000, simulate_batch(batch_size))
# Calculate probability of having at least 5 functional widgets in a batch
prob_at_least_5 <- mean(results)
cat("Batch size:", batch_size, "Probability of at least 5 functional widgets:", prob_at_least_5, "\n")
if (prob_at_least_5 >= target_prob) {
return(batch_size)
}
}
return(NA) # if no size meets the probability
}
# Find the minimum batch size that ensures at least 5 functional widgets with 99% probability
min_batch_size_mc <- find_batch_size(0.99)
cat("Monte Carlo Approach - Minimum batch size:", min_batch_size_mc, "\n")
p <- 0.82
required_prob <- 0.99
# Function to calculate the minimum batch size
min_batch_size <- function(p, required_prob) {
for (n in 1:1000) {  # Arbitrary large number for upper limit
prob <- 1 - pbinom(4, n, p)  # Probability of having at least 5 functional widgets
if (prob >= required_prob) {
return(n)
}
}
return(NULL)
}
# Calculate the minimum batch size
batch_size <- min_batch_size(p, required_prob)
cat("The minimum batch size to ensure at least 5 functional widgets with a probability of at least", required_prob, "is", batch_size, ".\n")
set.seed(1)
p_values <- seq(0.1, 0.9, 0.1)
coverage <- rep(0, length(p_values))
results <- data.frame(p = p_values, coverage = coverage)
NMC1 <- 500  # Number of Monte Carlo replicates for generating the confidence interval
NMC2 <- 500  # Number of replicates to construct each MC interval
# Loop through each value of p to estimate coverage
for (j in 1:nrow(results)) {
p <- results$p[j]  # Get the current p value from the data frame
contains <- rep(FALSE, NMC1)  # Track whether each CI contains the true p
for (i in 1:NMC1) {
# Step 1: Generate a sample of size 12 from the geometric distribution
sample_data <- rgeom(12, p)
# Step 2: Calculate the unbiased estimate of p
p_hat <- 1 / (1 + (12 / (12 - 1)) * mean(sample_data))
# Step 3: Use p_hat to generate NMC2 sets of data and calculate their p_hat estimates
p_hat_values <- rep(NA, NMC2)
for (k in 1:NMC2) {
sample_data_mc <- rgeom(12, p)  # Generate new sample
p_hat_values[k] <- 1 / (1 + (12 / (12 - 1)) * mean(sample_data_mc))  # Unbiased estimate
}
# Step 4: Construct a 95% confidence interval based on the quantiles of p_hat_values
lower_bound <- quantile(p_hat_values, 0.025)
upper_bound <- quantile(p_hat_values, 0.975)
# Step 5: Check if the true p is within the confidence interval
contains[i] <- (p >= lower_bound) & (p <= upper_bound)
}
# Step 6: Estimate the coverage rate by calculating the proportion of successful intervals
results[j, "coverage"] <- mean(contains)
}
# Plot the coverage rate
plot(x = results$p, y = results$coverage, ylim = c(min(coverage), 1), type = "l",
xlab = "p", ylab = "Coverage Rate", main = "Coverage Rate for Different p Values")
abline(h = 0.95, lty = 2)
set.seed(1)
p <- seq(.1,.9,.1)
coverage <- rep(0, length(p))
results <- data.frame(p, coverage)
NMC1 <- 500
NMC2 <- 500
for(j in 1:nrow(results)){
# pull out the value p from the results data frame
p <- results$p[j]
# the 'contains' vector will be a collection of TRUE and FALSE, based
# on whether each CI contains the value p
contains <- rep(FALSE, NMC1)
for(i in 1:NMC1){ #Construct NMC1 confidence intervals
#generate some data initially from the geometric distribution
#calculate the unbiased estimate of p
#Now you want to use your p.hat to generate NMC2 sets of data
#Each time you want to calcualte an unbiased phat, and store it.
#Your Monte Carlo Confidence interval should be based on
#appropriate sample quantiles
#Last, assign 'contains[i]' to be TRUE or FALSE based on
#whether p is >= than the lower bound AND <= the
#upper bound.
}
results[j, "coverage"] <- mean(contains)
}
plot(x=results$p, y=results$coverage, ylim=c(min(coverage),1), type="l")
abline(h=.95, lty=2)
set.seed(1)
p_values <- seq(0.1, 0.9, 0.1)  # p values to evaluate
coverage <- rep(0, length(p_values))
results <- data.frame(p = p_values, coverage = coverage)
NMC1 <- 500  # Number of Monte Carlo replicates for generating the confidence interval
NMC2 <- 500  # Number of replicates to construct each MC interval
sample_size <- 12  # Sample size
# Loop through each value of p to estimate coverage
for (j in 1:nrow(results)) {
p <- results$p[j]  # Get the current p value from the data frame
contains <- rep(FALSE, NMC1)  # Track whether each CI contains the true p
for (i in 1:NMC1) {
# Step 1: Generate a sample of size 12 from the geometric distribution
sample_data <- rgeom(sample_size, p)
# Step 2: Calculate the unbiased estimate of p
p_hat <- 1 / (1 + (sample_size / (sample_size - 1)) * mean(sample_data))
# Step 3: Use p_hat to generate NMC2 sets of data and calculate their p_hat estimates
p_hat_values <- rep(NA, NMC2)
for (k in 1:NMC2) {
sample_data_mc <- rgeom(sample_size, p)  # Generate new sample
p_hat_values[k] <- 1 / (1 + (sample_size / (sample_size - 1)) * mean(sample_data_mc))  # Unbiased estimate
}
# Step 4: Construct a 95% confidence interval based on the quantiles of p_hat_values
lower_bound <- quantile(p_hat_values, 0.025)
upper_bound <- quantile(p_hat_values, 0.975)
# Step 5: Check if the true p is within the confidence interval
contains[i] <- (p >= lower_bound) & (p <= upper_bound)
}
# Step 6: Estimate the coverage rate by calculating the proportion of successful intervals
results[j, "coverage"] <- mean(contains)
}
# Plot the coverage rate
plot(x = results$p, y = results$coverage, ylim = c(min(coverage), 1), type = "l",
xlab = "p", ylab = "Coverage Rate", main = "Coverage Rate for Different p Values")
abline(h = 0.95, lty = 2, col = "red")  # Add a horizontal line at 0.95 for reference
set.seed(1)
p_values <- seq(0.1, 0.9, 0.1)
coverage <- rep(0, length(p_values))
results <- data.frame(p = p_values, coverage = coverage)
NMC1 <- 500
NMC2 <- 500
n <- 12  # sample size
for (j in 1:nrow(results)) {
p <- results$p[j]
contains <- rep(FALSE, NMC1)
for (i in 1:NMC1) {
# Generate data from the geometric distribution
data <- rgeom(n, p)
x_bar <- mean(data)
# Calculate the unbiased estimate of p
p_hat <- 1 / (1 + (n / (n - 1)) * x_bar)
# Generate NMC2 sets of data using p_hat
p_hat_samples <- replicate(NMC2, {
sample_data <- rgeom(n, p_hat)
sample_x_bar <- mean(sample_data)
1 / (1 + (n / (n - 1)) * sample_x_bar)
})
# Calculate the 95% confidence interval
ci_lower <- quantile(p_hat_samples, 0.025)
ci_upper <- quantile(p_hat_samples, 0.975)
# Check if the true p is within the confidence interval
contains[i] <- (p >= ci_lower) & (p <= ci_upper)
}
# Calculate the coverage rate
results[j, "coverage"] <- mean(contains)
}
# Plot the coverage rate
plot(x = results$p, y = results$coverage, ylim = c(min(results$coverage), 1), type = "l",
xlab = "True p", ylab = "Coverage Rate", main = "Coverage Rate of 95% CI")
abline(h = 0.95, lty = 2)
deaths <- mule_kicks$deaths
ggplot(data.frame(deaths), aes(x = deaths)) +
geom_histogram(aes(y = ..density..), bins = 10, fill = 'skyblue', alpha = 0.7) +
stat_function(fun = dpois, args = list(lambda = mean(deaths)), color = 'red', size = 1) +
labs(title = "Histogram of Deaths with Poisson Fit",
x = "Number of Deaths",
y = "Density")
set.seed(123)
n_replicates <- 1000
# Number of Monte Carlo replicates
n_replicates <- 1000
alpha <- 0.05
# Function to generate a Monte Carlo sample and calculate the sample median
generate_sample_median <- function(a, b, n) {
sample <- runif(n, min = a, max = b)
sample_median <- median(sample)
return(sample_median)
}
# Generate Monte Carlo samples and calculate medians
monte_carlo_medians <- replicate(n_replicates, generate_sample_median(a_estimate, b_estimate, length(Data)))
# Calculate the confidence interval using the quantile function
ci_median_lower <- quantile(monte_carlo_medians, alpha / 2)
ci_median_upper <- quantile(monte_carlo_medians, 1 - alpha / 2)
# Output the results
cat(sprintf("Estimated minimum value (a_estimate): %f\n", a_estimate))
cat(sprintf("Estimated maximum value (b_estimate): %f\n", b_estimate))
cat(sprintf("95%% Confidence interval for the population median: [%f, %f]\n", ci_median_lower, ci_median_upper))
set.seed(123)
n_replicates <- 1000
# Number of Monte Carlo replicates
n_replicates <- 1000
alpha <- 0.05
# Function to generate a Monte Carlo sample and calculate the sample median
generate_sample_median <- function(a, b, n) {
sample <- runif(n, min = a, max = b)
sample_median <- median(sample)
return(sample_median)
}
# Generate Monte Carlo samples and calculate medians
monte_carlo_medians <- replicate(n_replicates, generate_sample_median(a_estimate, b_estimate, length(Data)))
# Calculate the confidence interval using the quantile function
ci_median_lower <- quantile(monte_carlo_medians, alpha / 2)
ci_median_upper <- quantile(monte_carlo_medians, 1 - alpha / 2)
cat(sprintf("95%% Confidence interval for the population median: [%f, %f]\n", ci_median_lower, ci_median_upper))
set.seed(42)
# Given data
Data <- c(16.91, 19.96, 16.55, 16.77, 19.64, 16.87, 16.50, 14.19, 16.54, 18.64, 11.27, 17.08)
# Estimate mean (mu) and standard deviation (sigma)
mean_X <- mean(Data)
sd_X <- sd(Data)
# Calculate the estimates for a and b
a <- mean_X - sqrt(3) * sd_X
b <- mean_X + sqrt(3) * sd_X
# Number of Monte Carlo replicates
num_replicates <- 1000
alpha <- 0.05
# Function to generate a Monte Carlo sample and calculate the sample median
generate_sample_median <- function(a, b, n) {
sample <- runif(n, min = a, max = b)
sample_median <- median(sample)
return(sample_median)
}
# Generate Monte Carlo samples and calculate medians
medians <- replicate(num_replicates, generate_sample_median(a, b, length(Data)))
# Calculate the confidence interval using the quantile function
lower_bound <- quantile(medians, alpha / 2)
upper_bound <- quantile(medians, 1 - alpha / 2)
# Output the results
cat(sprintf("Estimated minimum value (a): %f\n", a))
cat(sprintf("Estimated maximum value (b): %f\n", b))
cat(sprintf("95%% Confidence interval for the population median: [%f, %f]\n", lower_bound, upper_bound))
set.seed(123)
n_replicates <- 1000
alpha <- 0.05
# Function to generate a Monte Carlo sample and calculate the sample median
generate_sample_median <- function(a, b, n) {
sample <- runif(n, min = a, max = b)
sample_median <- median(sample)
return(sample_median)
}
# Generate Monte Carlo samples and calculate medians
monte_carlo_medians <- replicate(n_replicates, generate_sample_median(a_estimate, b_estimate, length(Data)))
# Calculate the confidence interval using the quantile function
ci_median_lower <- quantile(monte_carlo_medians, alpha / 2)
ci_median_upper <- quantile(monte_carlo_medians, 1 - alpha / 2)
cat(sprintf("95%% Confidence interval for the population median: [%f, %f]\n", ci_median_lower, ci_median_upper))
Data
mysteryData
