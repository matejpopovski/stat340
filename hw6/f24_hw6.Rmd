---
title: "Homework 6"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
library(tidyverse)
```

## Problem \#1: Testing coin flips <small>(6 pts)</small>

In the six sequences below, only one of them is actually **randomly generated from independent flips of a fair coin**. Use a combination of everything you know (common sense, Monte Carlo, hypothesis testing, etc.) to identify which is actually random and explain your reasoning.

(For full points, conduct a formal test and report a $p$-value for each sequence. You may use a combination of multiple tests to arrive at your answer. If you cannot compute a p-value for each sequence, you can still earn a significant amount of partial credit by carefully explaining your reasoning and response as best as you can.)

My advice is **be creative** with the test statistics you come up with to eliminate each sequence! Think of some way of summarizing a sequence of flips that might be useful for comparing against a simulated sequence of random flips. After you come up with an idea for a statistic, remember to run it on many MC generated completely random flips to produce a distribution under the null, which you can then compare with your data to get a p-value. Also, be careful of now you define "more extreme" than the data.

(2 bonus points available if you can find a single test that is powerful enough to reject all the fake sequences together in one step. Yes, at least one such possible test exists.)

```{r}
flips1 = "HTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHT"

flips2 = "HHHTHTTTHHTHHTHHHTTTTHTHTHHTTHTHHHTHHTHTTTHTHHHTHTTTHTHTHHTHTHTTHTHHTHTHTTTHTHHHTHTHTTHTHTHHTHTHTHHHTHTTTHTHHTHTHTHHTTTHTHHTHHTTTTHTHTHHHTHTTHTHHTHTHTTHTHHTHTHHHTHHHTHTTTHTTHTTTHTHHHTHTHTTHTHHTHHTHTTT"

flips3 = "HHTHTHTTTHTHHHTHHTTTHTHHTHTTTHTHTHHTHTHTTHTHHHHHHTTTHTHTHHTHTTTHTHHTHTHTTTHTHHHTTHTTTHTHTHHHHTHTTHHTTTTTHTHHHTHTHTTTTTHHHTHHTHHTHHHTTTTHTHTHHHTHHTTTTTHTHHHTHTHTHTTTHTHHHTHTHTHTTHTHHTHTHTHTTTTHTHHHTHTH"

flips4 = "HTHHHHHHHTHTTHHTTHHHTHTHTTTHHTHHHTHHTTHTTTTTTTTTHTHHTTTTTHTHTHTHHTTHTTHTTTTTHHHTHTTTHTHTHHHTHTTTTHTHTHHTTHTHTTHHTHTHHHHTHTTHHTTHTTHTTHTHHHHHHTTTTTTHHHTTHTHHHHTTTHTTHHHTTHTHHTTTHHTHHTTTHTHHTHHHTHHTTHHH"

flips5 = "HHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTT"

flips6 = "TTHTTTHTTTTTTTHTHTHTHTTHTTHTHHTHHTTTHHTHTTTHTHHTHHHTHTTHHTHHTTHTHTTTTHTHTTTHHTTTTTTTTHTHHTTHTTTTTTHTHTHTHTTTHTTHHTTHTTTHHTTTHTTHTTTTHTTTTHHTTTHTHTHHHTTTTTTHTHHTTTTTTTTTTTTHHHTTTHHHTTTHTTTHTHTTHTTTTTHT"

# you can use the function below to split the above sequences in vectors of flips
split = function(str) strsplit(str, split="")[[1]]
split(flips1)
```

> Before I start with the hypothesis testing, I can confidently say that flips1 and flips5 are not generated by a fair coin, because those series of H an T are extremely unusual. 

```{r}
# Function to find the longest run of heads ("H") in a vector of coin flips
longest_heads_run <- function(flips) {
  max_run <- 0   # Variable to store the maximum run of heads
  current_run <- 0  # Variable to count the current run of heads
  
  for (flip in flips) {
    if (flip == "H") {
      current_run <- current_run + 1  # Increment the current run of heads
    } else {
      if (current_run > max_run) {
        max_run <- current_run  # Update max_run if current_run is greater
      }
      current_run <- 0  # Reset the current run if the flip is not heads
    }
  }
  
  # Final check in case the longest run is at the end of the sequence
  if (current_run > max_run) {
    max_run <- current_run
  }
  
  return(max_run)
}

# Example usage
longest_heads_run(split(flips1))
longest_heads_run(split(flips2))
longest_heads_run(split(flips3))
longest_heads_run(split(flips4))
longest_heads_run(split(flips5))
longest_heads_run(split(flips6))

```

```{r}
# Function to simulate fair coin flips and find the longest run of heads
simulate_coin_flips <- function(n_flips) {
  flips <- sample(c("H", "T"), size = n_flips, replace = TRUE)  # Simulate fair coin flips
  return(longest_heads_run(flips))  # Return the longest run of heads
}

# Number of flips in each sequence
n_flips <- 200  # Adjust this to the actual length of your flip sequences

# Monte Carlo simulation to find the average longest run of heads over 10,000 trials
set.seed(123)
n_trials <- 10000
longest_runs <- numeric(n_trials)

for (i in 1:n_trials) {
  longest_runs[i] <- simulate_coin_flips(n_flips)
}

# Calculate the average longest run of heads from the Monte Carlo simulation
average_longest_run <- mean(longest_runs)
print(paste("Average longest run of heads from Monte Carlo simulation (using a fair coin):", average_longest_run))

# Compare with the longest run of heads from each provided sequence 
flips_list <- list(flips1, flips2, flips3, flips4, flips5, flips6)
results <- sapply(flips_list, function(flip_sequence) {
  flips_vector <- split(flip_sequence)
  longest_heads <- longest_heads_run(flips_vector)
  return(longest_heads)
})

# Combine the results
comparison <- data.frame(Sequence = paste0("Flips", 1:6),
                         LongestRun = results,
                         Difference = results - average_longest_run)

# Print comparison results
print(comparison)

```

> Null Hypothesis (H0): The observed sequence of flips is generated from a fair coin (i.e., the longest run of heads observed is consistent with the expected longest run from random flips).

> Alternative Hypothesis (H1): The observed sequence of flips is not generated from a fair coin (i.e., the longest run of heads observed is significantly greater than what would be expected from random flips).

```{r}
# Calculate p-values for each sequence
p_values <- sapply(results, function(longest_run) {
  # P-value is the proportion of simulated runs that are less than or equal to the longest run
  mean(longest_runs <= longest_run)
})

# Combine the results into a data frame
comparison <- data.frame(Sequence = paste0("Flips", 1:6),
                         LongestRun = results,
                         PValue = p_values)

# Print comparison results
print(comparison)


```

> Since I have previously stated that flip5 is not generated by a fair coin, the closest one after that is flip4. 


## Problem \#2: Finding the Trick Coin <small>(6 pts; 2pts each)</small>

I have two coins in my pocket - a trick coin with two heads and a fair coin with one head and one tail(s?). We'll play a game. I will grab one coin at random, and flip it $N$ times. After that you will have to decide if it is the fair coin or the trick coin. The null hypothesis is that it is the fair coin. 

**Decision Rule 1**: If after $N$ flips there are no tails, then you decide it is the trick coin. If there is at least 1 tail then you know it is the fair coin. 

a. Using "Decision Rule 1", what is the lowest number of flips $N$ would you need in order to have a significance level less than 5% for this test?

> The probability of getting no tails in N flips of a fair coin, which has a probability of getting heads of 0.5, is given by P(no tails) equals 0.5 raised to the power of N. To find N such that 0.5 raised to the power of N is less than 0.05, we need to solve this inequality.

> P(no tails) = 0.5^N  to find such that  0.5^N < 0.05

> The minimum number of flips we need is 5, after that we would be able to conclude whther the coin was fair or trick.

b. Using $N$ from part a, what is the power of the test?

> To calculate the power of the test with N equals 5, we use the formula:

> Power = 1 - P(no tails), which is equal to 1 - 0.5 ^ N.

> For N = 5, we first calculate P(no tails):

> P(no tails) = 0.5 ^ 5, which equals 1 / 32, approximately 0.03125.

> Next, we calculate the power:

> Power = 1 - P(no tails) = 1 - 0.5 ^ 5, which equals 1 - 0.03125, resulting in approximately 0.96875.

> Thus, the power of the test when N equals 5 is approximately 0.96875, meaning there is a 96.875% chance of correctly rejecting the null hypothesis if the chosen coin is the fair coin.

c. Suppose $N=4$ is decided. How can you modify the decision process to have a significance level of exactly 5%? Does this change the power of the test?

> The current decision rule is to reject the null hypothesis (the coin is fair) if there are 0 tails in 4 flips. This gives a significance level of P(0 tails) equals 0.5 raised to the power of 4, which equals 0.0625.

> To achieve exactly a 5% significance level, we can modify the rule to reject the null hypothesis if there are 0 or 1 tails. This gives us the probability of 0 tails, which remains 0.0625, and the probability of 1 tail can be calculated as follows: P(1 tail) equals 4 choose 1 times 0.5 raised to the power of 1 times 0.5 raised to the power of 3, which results in 4 times 0.5 times 0.125, equaling 0.25.

> The total significance level becomes alpha equals 0.0625 plus 0.25, which equals 0.3125, indicating it is too high.

> For the final adjustment to lower the significance level to exactly 5%, we may need to adjust the conditions further or limit the number of heads allowed to achieve the exact probability of rejecting the null hypothesis.

> Regarding the power of the test with the modified rule (rejecting for 0 or 1 tails), if the trick coin is chosen, you will always see 0 tails, so the power remains equal to 1.


d. Extra Credit (2 points): Suppose if you guess correct you win \$100 (and if you're wrong you get nothing), but each flip of the coin costs \$10. What strategy would you use to maximize your expected profit from this game?

> For N=1: Probability = 0.50     1-1/2     E(1)=0.50*100-10=40

> For N=2: Probability = 0.75     1-1/2^2     E(2)=0.75*100-20=55
 
> For N=3: Probability = 0.875     1-1/2^3     E(3)=0.875*100-30=57.50

> For N=4: Probability = 0.9375     1-1/2^4     E(4)=0.9375*100-40=53.75



## Problem \#3: Testing the maximum of a uniform distribution <small>(8 pts; 2 pts each)</small>

We sample $X_1, X_x,\ldots,X_n \overset{\text{iid}}\sim\text{Uniform}(0,m)$ where $m$ is an unknown maximum. Sleazy Jim tells you that $m=1$ but you're not so sure. The 50 values sampled are in the following data file:

```{r}
X <- read.csv("uniform_sample.csv")$x
head(X)
```

a. Write out in formal notation the null and alternative hypotheses. 

> H0: m = 1    (uniform distribution over [0,1])

> H1: m != 1   (actual m is not 1)

b. Come up with a test statistic and measure your sampled data. Is this a one-sided test or two-sided test?

> Test statistic T=Xmax   where Xmax=max(x1,.....xn)=  9.944338254

> It is two-sided test because we want to test friends claim that m=1  and actually do not know direction of the claim, is m>1 or m<1. 

c. Simulate a distribution for the test statistic under the null hypothesis of size at least 1000. Display a histogram of your test statistic distribution.

```{r}
n <- 50  # Sample size
M <- 1000  # Number of simulations

# Simulate the maximum values of uniform distribution over [0,1]
sim_max <- replicate(M, max(runif(n, 0, 1)))
#sim_max
mean(sim_max)
# Plot the histogram
hist(sim_max, breaks = 30, main = "Simulated Distribution of Max Values (Under H0)",
     xlab = "Max Value", col = "lightblue")

# Observed max from the sample
obs_max<- max(X)
obs_max

# Calculate the p-value simulated max greater than observed
p_value <- mean(sim_max >= obs_max)
p_value
# Calculate the p-value simulated max smaler than observed
p_value <- mean(sim_max <= obs_max)
p_value
```


d. Calculate the $p$-value for this data and make a conclusion.

Calculated p>0.05 so we fail to reject H0. There is not enough evidence to reject m=1

## Problem \#4: Blurtle <small>(10 pts; 2 pt each)</small>

Have you been playing the hot new game Blurtle? It's a (fictional) word game you can play daily - you have to guess a 5 letter word and you only have 6 attempts. I've been playing for the past 100 days and I've been tracking my number of guesses. I'm trying to figure out whether I have been getting better or not.

The file `blurtle.csv` contains 100 rows of data, giving the number of tries to guess the word. If it took 7 guesses that actually means I failed (you don't actually get a 7th guess). 

Your task is to perform a permutation test on the data to determine if there is statistical evidence of a true improvement trend.

a. State the null and alternative hypotheses
H0: There is no change in the trend in the number of tries.
H1: There is change in the trend in the number of tries

b. Determine a test statistic that identifies a trend in the number of tries. There are many good ones you could use - be creative.


c. Decide whether the test will be a one or two-tailed test
Two-tailed test is used because we are looking for either improvement or deterioration  - lower or greater number of guesses.

d. Simulate a distribution of test statistics under the null hypothesis
e. Calculate the test statistic on the observed data, calculate the $p$-value and state your conclusions.

```{r}
blurtle <- read.csv("blurtle.csv")

#blurtle
#blurtle$tries
#mean(blurtle$tries)
#var(blurtle$tries)

# Compute observed test statistic
observed_stat <- cor(blurtle$day, blurtle$tries, method = "spearman")

# Permutation test function
perm_test <- function(data, n_perm = 1000) {
  perm_stats <- numeric(n_perm)
  
  for (i in 1:n_perm) {
    perm_data <- data
    perm_data$tries <- sample(perm_data$tries)
    perm_stats[i] <- cor(perm_data$day, perm_data$tries, method = "spearman")
  }
  
  return(perm_stats)
}

set.seed(123)
perm_stats <- perm_test(blurtle)

# Calculate p-value
p_value <- (sum(abs(perm_stats) >= abs(observed_stat)) + 1) / (length(perm_stats) + 1)

# Plot distribution of permutation test statistics
hist(perm_stats, main = "Permutation Test Statistics", xlab = "Spearman Correlation", breaks = 30)
abline(v = observed_stat, col = "red", lwd = 2)

# Print results
print(paste("Observed test statistic: ", observed_stat))
print(paste("P-value: ", p_value))
```
We conclude that there is enough evidence to reject the H0 hypothesis. Test statistic has negative value meaning that there is enough evidence that number of guesses by days is lowering.


