---
title: "Homework 6"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo=T,eval=T,message=F,warning=F,fig.align='center')
library(tidyverse)
```

## Problem \#1: Testing coin flips <small>(6 pts)</small>

In the six sequences below, only one of them is actually **randomly generated from independent flips of a fair coin**. Use a combination of everything you know (common sense, Monte Carlo, hypothesis testing, etc.) to identify which is actually random and explain your reasoning.

(For full points, conduct a formal test and report a $p$-value for each sequence. You may use a combination of multiple tests to arrive at your answer. If you cannot compute a p-value for each sequence, you can still earn a significant amount of partial credit by carefully explaining your reasoning and response as best as you can.)

My advice is **be creative** with the test statistics you come up with to eliminate each sequence! Think of some way of summarizing a sequence of flips that might be useful for comparing against a simulated sequence of random flips. After you come up with an idea for a statistic, remember to run it on many MC generated completely random flips to produce a distribution under the null, which you can then compare with your data to get a p-value. Also, be careful of now you define "more extreme" than the data.

(2 bonus points available if you can find a single test that is powerful enough to reject all the fake sequences together in one step. Yes, at least one such possible test exists.)

```{r}
flips1 = "HTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHTHT"

flips2 = "HHHTHTTTHHTHHTHHHTTTTHTHTHHTTHTHHHTHHTHTTTHTHHHTHTTTHTHTHHTHTHTTHTHHTHTHTTTHTHHHTHTHTTHTHTHHTHTHTHHHTHTTTHTHHTHTHTHHTTTHTHHTHHTTTTHTHTHHHTHTTHTHHTHTHTTHTHHTHTHHHTHHHTHTTTHTTHTTTHTHHHTHTHTTHTHHTHHTHTTT"

flips3 = "HHTHTHTTTHTHHHTHHTTTHTHHTHTTTHTHTHHTHTHTTHTHHHHHHTTTHTHTHHTHTTTHTHHTHTHTTTHTHHHTTHTTTHTHTHHHHTHTTHHTTTTTHTHHHTHTHTTTTTHHHTHHTHHTHHHTTTTHTHTHHHTHHTTTTTHTHHHTHTHTHTTTHTHHHTHTHTHTTHTHHTHTHTHTTTTHTHHHTHTH"

flips4 = "HTHHHHHHHTHTTHHTTHHHTHTHTTTHHTHHHTHHTTHTTTTTTTTTHTHHTTTTTHTHTHTHHTTHTTHTTTTTHHHTHTTTHTHTHHHTHTTTTHTHTHHTTHTHTTHHTHTHHHHTHTTHHTTHTTHTTHTHHHHHHTTTTTTHHHTTHTHHHHTTTHTTHHHTTHTHHTTTHHTHHTTTHTHHTHHHTHHTTHHH"

flips5 = "HHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTTHHHHHHHHHHTTTTTTTTTT"

flips6 = "TTHTTTHTTTTTTTHTHTHTHTTHTTHTHHTHHTTTHHTHTTTHTHHTHHHTHTTHHTHHTTHTHTTTTHTHTTTHHTTTTTTTTHTHHTTHTTTTTTHTHTHTHTTTHTTHHTTHTTTHHTTTHTTHTTTTHTTTTHHTTTHTHTHHHTTTTTTHTHHTTTTTTTTTTTTHHHTTTHHHTTTHTTTHTHTTHTTTTTHT"

# you can use the function below to split the above sequences in vectors of flips
split = function(str) strsplit(str, split="")[[1]]
split(flips1)
fl1<-split(flips1)

split(flips2)
fl2<-split(flips2)

#haming

# Function to calculate Hamming distance
hamming_distance <- function(seq1, seq2) {
  sum(seq1 != seq2)
}

# Function to perform the permutation test using Hamming distance
hamming_permutation_test <- function(observed_seq, num_permutations = 1000) {
  # Calculate the observed Hamming distance (comparing the sequence to itself to set a baseline)
  observed_distance <- hamming_distance(observed_seq, observed_seq)
  
  # Vector to store the Hamming distances for each permutation
  permuted_distances <- numeric(num_permutations)
  
  # Perform permutations
  for (i in 1:num_permutations) {
    # Permute the sequence randomly
    permuted_seq <- sample(observed_seq)
    
    # Calculate the Hamming distance between the original and permuted sequence
    permuted_distances[i] <- hamming_distance(observed_seq, permuted_seq)
  }
  
  # Calculate the p-value
  p_value <- mean(permuted_distances >= observed_distance)
  
  # Return results
  list(
    observed_distance = observed_distance,
    permuted_distances = permuted_distances,
    p_value = p_value
  )
}

# Example sequence (binary sequence of heads (H) and tails (T))
#observed_seq <- c("H", "T", "H", "H", "T", "T", "H", "T", "H", "H")

# Run the Hamming distance permutation test
result <- hamming_permutation_test(fl1, num_permutations = 1000)

# Display the results
cat("Observed Hamming Distance:", result$observed_distance, "\n")
cat("P-value:", result$p_value, "\n")





```



## Problem \#2: Finding the Trick Coin <small>(6 pts; 2pts each)</small>

I have two coins in my pocket - a trick coin with two heads and a fair coin with one head and one tail(s?). We'll play a game. I will grab one coin at random, and flip it $N$ times. After that you will have to decide if it is the fair coin or the trick coin. The null hypothesis is that it is the fair coin. 

**Decision Rule 1**: If after $N$ flips there are no tails, then you decide it is the trick coin. If there is at least 1 tail then you know it is the fair coin. 

a. Using "Decision Rule 1", what is the lowest number of flips $N$ would you need in order to have a significance level less than 5% for this test?
b. Using $N$ from part a, what is the power of the test?
c. Suppose $N=4$ is decided. How can you modify the decision process to have a significance level of exactly 5%? Does this change the power of the test?
d. Extra Credit (2 points): Suppose if you guess correct you win \$100 (and if you're wrong you get nothing), but each flip of the coin costs \$10. What strategy would you use to maximize your expected profit from this game?


## Problem \#3: Testing the maximum of a uniform distribution <small>(8 pts; 2 pts each)</small>

We sample $X_1, X_x,\ldots,X_n \overset{\text{iid}}\sim\text{Uniform}(0,m)$ where $m$ is an unknown maximum. Sleazy Jim tells you that $m=1$ but you're not so sure. The 50 values sampled are in the following data file:

```{r}
X <- read.csv("uniform_sample.csv")$x
```

a. Write out in formal notation the null and alternative hypotheses. 
b. Come up with a test statistic and measure your sampled data. Is this a one-sided test or two-sided test?
c. Simulate a distribution for the test statistic under the null hypothesis of size at least 1000. Display a histogram of your test statistic distribution.
d. Calculate the $p$-value for this data and make a conclusion.

## Problem \#4: Blurtle <small>(10 pts; 2 pt each)</small>

Have you been playing the hot new game Blurtle? It's a (fictional) word game you can play daily - you have to guess a 5 letter word and you only have 6 attempts. I've been playing for the past 100 days and I've been tracking my number of guesses. I'm trying to figure out whether I have been getting better or not.

The file `blurtle.csv` contains 100 rows of data, giving the number of tries to guess the word. If it took 7 guesses that actually means I failed (you don't actually get a 7th guess). 

```{r}
blurtle <- read.csv("blurtle.csv")
```

Your task is to perform a permutation test on the data to determine if there is statistical evidence of a true improvement trend.

a. State the null and alternative hypotheses
b. Determine a test statistic that identifies a trend in the number of tries. There are many good ones you could use - be creative.
c. Decide whether the test will be a one or two-tailed test
d. Simulate a distribution of test statistics under the null hypothesis
e. Calculate the test statistic on the observed data, calculate the $p$-value and state your conclusions.


